# üöÄ Inicio R√°pido - Sistema Completo Chatbot Celsia

Esta gu√≠a te ayudar√° a poner en marcha el sistema completo (Backend + Frontend) en minutos.

---

## üìã Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:

1. **Python 3.8+** (con uv o pip)
2. **Ollama** con el modelo `qwen3:4b`
3. **Google API Key** para embeddings
4. **Navegador web moderno**

---

## ‚ö° Pasos de Inicio R√°pido

### 1Ô∏è‚É£ Configurar Variables de Entorno

Verifica que tu archivo `.env` contenga:

```env
# Modelo LLM
OLLAMA_LLM_MODEL=qwen3:4b
OLLAMA_BASE_URL=http://localhost:11434

# Google API Key para embeddings
GOOGLE_API_KEY=tu_clave_aqui

# LangSmith (Opcional)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=tu_clave_langsmith
LANGCHAIN_PROJECT=Celsia Chatbot
```

### 2Ô∏è‚É£ Iniciar Ollama

En una terminal:

```bash
ollama serve
```

Verifica que el modelo est√© descargado:

```bash
ollama list
# Si no est√° qwen3:4b, desc√°rgalo:
ollama pull qwen3:4b
```

### 3Ô∏è‚É£ Iniciar el Backend (API FastAPI)

En una **nueva terminal**, desde la ra√≠z del proyecto:

```bash
# Activar entorno virtual
.\.venv\Scripts\Activate.ps1  # Windows PowerShell
# o
source .venv/bin/activate  # Linux/Mac

# Iniciar el servidor FastAPI
uvicorn main:app --host 0.0.0.0 --port 8000
```

Deber√≠as ver:
```
‚úÖ Agent components loaded successfully.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**Verificar el API**: Abre http://localhost:8000/health en tu navegador.

### 4Ô∏è‚É£ Iniciar el Frontend

**Opci√≥n A: Abrir directamente (simple, pero puede tener problemas CORS)**

```bash
start frontend\index.html
```

O simplemente haz doble clic en `frontend/index.html`

**Opci√≥n B: Servidor HTTP local (recomendado)**

En una **tercera terminal**:

```bash
# Usando Python
cd frontend
python -m http.server 8080

# O si tienes Node.js con http-server
npx http-server -p 8080
```

Luego abre: http://localhost:8080

---

## ‚úÖ Verificaci√≥n

Una vez que todo est√© ejecut√°ndose:

1. ‚úÖ **Ollama**: Terminal 1 ejecutando `ollama serve`
2. ‚úÖ **Backend API**: Terminal 2 ejecutando `uvicorn` en http://localhost:8000
3. ‚úÖ **Frontend**: Terminal 3 (opcional) ejecutando servidor HTTP en http://localhost:8080

### Probar el Sistema

1. Abre el frontend en tu navegador
2. Escribe un mensaje de prueba: "Hola, ¬øqu√© es Celsia?"
3. Deber√≠as ver el indicador de "escribiendo..." y luego una respuesta del bot

---

## üêõ Soluci√≥n R√°pida de Problemas

### ‚ùå Error: "No se pudo conectar con el servidor"

**Causa**: El backend no est√° ejecut√°ndose.

**Soluci√≥n**: Verifica que el servidor FastAPI est√© corriendo y accesible en http://localhost:8000/health

### ‚ùå Error CORS

**Causa**: Abriste el `index.html` directamente sin servidor HTTP.

**Soluci√≥n**: Usa la Opci√≥n B (servidor HTTP local) del paso 4.

### ‚ùå Error: "Agent not loaded yet"

**Causa**: Problemas con Ollama, Google API Key o ChromaDB.

**Soluci√≥n**:
1. Verifica que Ollama est√© ejecut√°ndose: `ollama list`
2. Verifica tu `GOOGLE_API_KEY` en `.env`
3. Verifica que existe la carpeta `chromadb_storage` (si no, ejecuta `python regenerate_chromadb.py`)

### ‚ùå El logo no aparece

**Causa**: Falta el archivo del logo.

**Soluci√≥n**: Coloca `celsia-logo.png` en `frontend/assets/` (el sistema funcionar√° sin logo, solo no se mostrar√°)

---

## üéØ URLs Importantes

| Servicio | URL | Descripci√≥n |
|----------|-----|-------------|
| **Backend API** | http://localhost:8000 | API FastAPI |
| **API Docs** | http://localhost:8000/docs | Swagger UI interactivo |
| **Health Check** | http://localhost:8000/health | Estado del servidor |
| **Frontend** | http://localhost:8080 | Interfaz del chatbot |
| **Ollama** | http://localhost:11434 | Servidor Ollama |

---

## üìù Comandos √ötiles

### Ver logs del backend
El servidor FastAPI muestra los logs directamente en la terminal donde lo iniciaste.

### Detener todo
1. Presiona `Ctrl+C` en cada terminal para detener los servicios
2. Cierra el navegador

### Limpiar historial del chat
- Desde el frontend: Click en el icono de papelera
- Desde el navegador: Borrar localStorage (F12 ‚Üí Application ‚Üí Local Storage)

### Regenerar base de datos vectorial
Si actualizaste los documentos fuente:

```bash
python regenerate_chromadb.py
```

---

## üé® Personalizaci√≥n R√°pida

### Cambiar colores
Edita `frontend/styles.css` l√≠neas 4-17 (variables CSS)

### Cambiar puerto del frontend
Modifica el puerto en el comando del servidor HTTP:
```bash
python -m http.server 9000  # Usa puerto 9000
```

Luego actualiza `frontend/script.js` l√≠nea 4 si es necesario.

### Cambiar puerto del backend
```bash
uvicorn main:app --port 8080
```

No olvides actualizar `frontend/script.js` l√≠nea 4 con la nueva URL.

---

## üìö Documentaci√≥n Adicional

- **Frontend**: Ver `frontend/README.md`
- **Backend**: Ver `README.md` principal
- **API**: http://localhost:8000/docs (cuando el servidor est√© corriendo)

---

## üéâ ¬°Listo!

Ahora tienes el chatbot de Celsia funcionando completamente. Puedes:

- Hacer preguntas sobre Celsia
- Ver el historial de conversaciones
- Limpiar el chat
- Personalizar los colores y estilos

**¬°Disfruta usando el Asistente Virtual de Celsia! üöÄ‚ö°**
