# üìò Proyecto M√≥dulo 1 ‚Äì Construcci√≥n de la Capa de Conocimiento  
**Empresa Asignada:** CELSIA  
**Grupo:** 1  
**Integrantes:**    
Estudiante: Jonathan Giraldo Diaz Ortega - cod 22501577   
Estudiante: Jhon Stiven Loaiza Rodriguez - cod 22500235   
Estudiante: Eliphas Levi Arias Abrahan - cod 22500217   
Estudiante: Juan Manuel Cajigas Eraso - cod 22500447    
**M√≥dulo:** Capa de Conocimiento  
**Duraci√≥n:** Fase 1 ‚Äì Extracci√≥n, Procesamiento y Demostraci√≥n de la Base de Conocimiento  

---

## 1Ô∏è‚É£ Asignaci√≥n de Empresa y An√°lisis Inicial (Investigaci√≥n)

### üîπ Asignaci√≥n
La empresa asignada es **CELSIA**, compa√±√≠a del **Grupo Argos**, dedicada a la generaci√≥n, transmisi√≥n y comercializaci√≥n de energ√≠a el√©ctrica en Colombia, con un enfoque estrat√©gico en **energ√≠as renovables y eficiencia energ√©tica**.  

### üîπ Investigaci√≥n y Fuentes Consultadas
Se realiz√≥ una investigaci√≥n exhaustiva en las siguientes fuentes de informaci√≥n p√∫blica y digital:  

- **Sitio web oficial:** [https://www.celsia.com/](https://www.celsia.com/)  
  - Secciones analizadas: *Qui√©nes somos, Estrategia sostenible, Soluciones energ√©ticas, Noticias, Inversionistas y Atenci√≥n al cliente*.  
- **Perfil oficial en LinkedIn:** [https://www.linkedin.com/company/celsiaenergia/](https://www.linkedin.com/company/celsiaenergia/)  
  - Publicaciones sobre proyectos de innovaci√≥n, energ√≠as limpias, reconocimientos, convocatorias laborales y acciones de sostenibilidad.  

### üîπ Definici√≥n del Alcance
El sistema Q&A debe responder preguntas frecuentes que un usuario o cliente podr√≠a hacer al interactuar por primera vez con la empresa.  

Ejemplos de temas incluidos en el alcance:

| Categor√≠a | Tipo de Pregunta |
|------------|------------------|
| Informaci√≥n general | ¬øQu√© es Celsia?, ¬øA qu√© grupo empresarial pertenece?, ¬øD√≥nde opera? |
| Servicios | ¬øQu√© soluciones de energ√≠a ofrece?, ¬øC√≥mo puedo generar energ√≠a solar con Celsia? |
| Sedes y contacto | ¬øD√≥nde est√°n las oficinas de atenci√≥n?, ¬øC√≥mo contactar soporte? |
| Facturaci√≥n y pagos | ¬øD√≥nde se pueden realizar pagos?, ¬øC√≥mo consultar el estado de la factura? |
| Responsabilidad social | ¬øQu√© programas de sostenibilidad tiene Celsia? |
| Noticias e innovaci√≥n | ¬øQu√© proyectos recientes ha desarrollado Celsia? |

---

## 2Ô∏è‚É£ Construcci√≥n de la Base de Conocimiento Sem√°ntico - Arquitectura Propuesta

![alt text](Arquitectura.drawio.png)

La arquitectura propuesta se basa en un flujo secuencial de componentes que automatizan la adquisici√≥n, procesamiento, almacenamiento y consulta de informaci√≥n. Cada m√≥dulo cumple un rol espec√≠fico dentro del ecosistema del canal inteligente de Celsia:

### üîπ Selenium ‚Äì Extracci√≥n Autom√°tica de Datos  
El proceso se inicia con **Selenium**, una herramienta de automatizaci√≥n web que permite realizar **web scraping controlado** sobre los portales oficiales de Celsia.  
Este componente navega por las p√°ginas y extrae la informaci√≥n relevante (por ejemplo, puntos de pago, noticias, procesos de facturaci√≥n, tarifas, y servicios disponibles), garantizando que los datos est√©n siempre actualizados.

### üîπ JSON ‚Äì Estructuraci√≥n de la Informaci√≥n  
Los datos obtenidos mediante Selenium se almacenan en **formato JSON**, lo que facilita su posterior manipulaci√≥n, transporte e integraci√≥n con otros m√≥dulos del sistema.  
El formato JSON permite mantener una estructura clara y jer√°rquica de la informaci√≥n, representando eficientemente texto, categor√≠as y metadatos.

### üîπ Pandas ‚Äì Procesamiento y Limpieza de Datos  
Con el archivo JSON como entrada, **Pandas** se encarga de realizar la **limpieza, normalizaci√≥n y estructuraci√≥n tabular** de los datos.  
Este paso incluye la eliminaci√≥n de duplicados, la estandarizaci√≥n de campos y la organizaci√≥n de los registros para su posterior indexaci√≥n sem√°ntica.

### üîπ ChromaDB ‚Äì Almacenamiento Vectorial Sem√°ntico  
Una vez procesada, la informaci√≥n se transforma en **vectores embebidos** y se almacena en **ChromaDB**, una base de datos vectorial optimizada para b√∫squedas sem√°nticas.  
Este componente permite que el asistente realice consultas basadas en el significado del texto (no solo coincidencias literales), mejorando la precisi√≥n de las respuestas ante preguntas de los usuarios.

### üîπ Ollama ‚Äì Modelo de Lenguaje Local  
**Ollama** act√∫a como el motor de inteligencia artificial local que ejecuta **modelos de lenguaje (LLMs)** preentrenados.  
Este modelo interpreta las consultas del usuario, accede a los vectores relevantes en ChromaDB y genera respuestas coherentes, naturales y ajustadas al contexto de la empresa.

### üîπ LangChain ‚Äì Orquestaci√≥n de Procesos y Consultas  
**LangChain** coordina la interacci√≥n entre todos los m√≥dulos del sistema.  
Define la l√≥gica de flujo: recibe la consulta del usuario, consulta el vector store (ChromaDB), formatea la respuesta con el modelo Ollama y la devuelve al canal de comunicaci√≥n (Streamlit).  
LangChain tambi√©n gestiona el *prompting* y los *retrieval chains*, garantizando consistencia y trazabilidad en las respuestas.

### üîπ Streamlit ‚Äì Interfaz de Usuario  
Finalmente, **Streamlit** provee una interfaz web interactiva donde el usuario puede comunicarse con el asistente.  
El chat permite ingresar consultas en lenguaje natural y visualizar respuestas generadas din√°micamente por el modelo.  
Adem√°s, Streamlit facilita el despliegue del sistema y su acceso desde diferentes dispositivos.


## 3Ô∏è‚É£ Construcci√≥n del Aplicativo

### üîπ Selecci√≥n del Modelo y Framework
Para esta primera versi√≥n del sistema Q&A se seleccion√≥ la siguiente configuraci√≥n:

| Componente | Tecnolog√≠a Elegida | Justificaci√≥n |
|-------------|--------------------|----------------|
| **Modelo LLM** | **Gemma 3 4B (Google, v√≠a Ollama)** | Modelo open source liviano (4 billones de par√°metros), optimizado para comprensi√≥n y generaci√≥n de texto en espa√±ol e ingl√©s. Ofrece un excelente equilibrio entre **rendimiento y eficiencia computacional**, ideal para ejecuci√≥n local o en entornos acad√©micos sin GPU de alto costo. Adem√°s, presenta baja tasa de alucinaciones y buen desempe√±o en tareas de **retrieval-based Q&A**. |
| **Framework de orquestaci√≥n** | **LangChain** | Permite integrar el modelo, embeddings y base vectorial en un pipeline RAG (Retrieval-Augmented Generation) modular y escalable. Facilita la construcci√≥n del prompt y la cadena de recuperaci√≥n. |
| **Embeddings** | `nomic-embed-text ` | Modelo de Embeddings de Texto de c√≥digo abierto. Un modelo de embeddings transforma el texto (palabras, frases, documentos) en vectores num√©ricos (listas de n√∫meros) que capturan su significado sem√°ntico. |
| **Base de datos vectorial** | **ChromaDB (open source)** | Ligera, eficiente y de integraci√≥n directa con LangChain; ideal para almacenar y consultar embeddings de texto. |

---

### üîπ Arquitectura General del Sistema RAG
1. **Consulta del usuario** ‚Üí Entrada en interfaz (Streamlit).  
2. **B√∫squeda sem√°ntica** ‚Üí El texto de la pregunta se convierte en embedding y se compara con los embeddings de los chunks almacenados en ChromaDB.  
3. **Recuperaci√≥n de contexto relevante** ‚Üí Se extraen los fragmentos m√°s similares.  
4. **Generaci√≥n de respuesta** ‚Üí El modelo Gemma 3 4B utiliza el contexto recuperado para elaborar una respuesta precisa y contextualizada.  

---

### üîπ Aplicaci√≥n de Prompt Engineering
Se dise√±√≥ un prompt de sistema robusto con las siguientes instrucciones:

```
"""**[INSTRUCCIONES CLAVE ZERO-SHOT Y LIMITACI√ìN DE FUENTE]**
Tu √öNICA tarea es responder a la **PREGUNTA** del usuario, utilizando EXCLUSIVAMENTE la informaci√≥n que se encuentra en el **CONTEXTO** proporcionado a continuaci√≥n.

**REGLAS ESTRICTAS para evitar alucinaciones:**
1.  **SI** la respuesta a la PREGUNTA se encuentra expl√≠cita o impl√≠citamente en el **CONTEXTO**, genera una respuesta completa y profesional.
2.  **SI** no puedes encontrar la respuesta en el **CONTEXTO**, o si la informaci√≥n es insuficiente, debes responder **√öNICAMENTE** con la siguiente frase predefinida: "Lamento no poder ofrecer una respuesta precisa basada en la informaci√≥n disponible. Por favor, consulta los canales oficiales de CELSIA o llama a la l√≠nea de servicio al cliente."
3.  **NUNCA** utilices tu conocimiento general o informaci√≥n que no est√© en el **CONTEXTO**. **NUNCA** inventes tarifas, fechas o procesos.
Coloca el cursor sobre un mensaje para fijarlo

Contexto:
{context}

Pregunta: {question}

Respuesta:"""
```

El contexto se completa din√°micamente con los fragmentos recuperados desde ChromaDB antes de cada consulta del usuario.

---

## 4Ô∏è‚É£ Desarrollo de la Interfaz de Prueba

Se implement√≥ una interfaz web simple utilizando **Streamlit**, la cual permite:

- Un campo de entrada para la pregunta del usuario.  
- Visualizaci√≥n de la respuesta generada por el sistema.  
- Visualizaci√≥n de los fragmentos de contexto utilizados para la respuesta.  

## 5Ô∏è‚É£ Pruebas, Documentaci√≥n y Presentaci√≥n

### üîπ Pruebas
Se realizaron **20 preguntas de validaci√≥n** basadas en el alcance definido.  
Ejemplos:

| Pregunta | Respuesta esperada | Resultado del sistema |
|-----------|--------------------|------------------------|
| ¬øQu√© es Celsia? | Empresa del Grupo Argos dedicada a la generaci√≥n y comercializaci√≥n de energ√≠a. | ‚úÖ Precisa |
| ¬øD√≥nde puedo pagar mi factura? | En puntos autorizados y en l√≠nea a trav√©s del portal web. | ‚úÖ Precisa |
| ¬øQu√© programas de sostenibilidad tiene Celsia? | Energ√≠a solar comunitaria y reforestaci√≥n. | ‚úÖ Parcialmente completa |
| ¬øCelsia ofrece energ√≠a e√≥lica? | S√≠, participa en proyectos de energ√≠a e√≥lica. | ‚úÖ Correcta |

El modelo **Gemma 3 4B** mostr√≥ **alta coherencia y baja tasa de alucinaciones**, especialmente cuando se le restringe al contexto relevante.

### üîπ Descripci√≥n del Problema
Necesidad de un canal de comunicaci√≥n automatizado y preciso para la empresa **CELSIA**, donde los usuarios puedan consultar informaci√≥n de la empresa, puntos de pago, procesos de facturaci√≥n y dem√°s servicios prestados por la entidad.

### üîπ Planteamiento de la Soluci√≥n
Creaci√≥n de un **sistema Q&A basado en RAG** como n√∫cleo de un futuro chatbot, alimentado con informaci√≥n extra√≠da desde el sitio web y el perfil corporativo de LinkedIn de la empresa.

### üîπ Preparaci√≥n de los Datos
Se realiz√≥ la extracci√≥n de los datos utilizando **Selenium**, exportando los textos a **JSON**. Luego se ejecut√≥ un proceso de limpieza (eliminaci√≥n de HTML, s√≠mbolos y espacios no relevantes) y segmentaci√≥n en **chunks** almacenados en un archivo CSV, conformando la base de conocimiento para la fase de modelado.

### üîπ Modelado
El sistema combina tres componentes principales:
- **Modelo de Embeddings:** all-MiniLM-L6-v2 (open source, eficiente en generaci√≥n de representaciones vectoriales).
- **LLM:** Gemma 3 4B, modelo base para la generaci√≥n de respuestas contextuales.
- **Base Vectorial:** ChromaDB, por su simplicidad, escalabilidad y compatibilidad con LangChain.

El dise√±o del prompt instruye al modelo a responder exclusivamente con base en la informaci√≥n recuperada, manteniendo precisi√≥n y coherencia.

### üîπ Resultados
Se realizaron **20 pruebas** con preguntas comunes de usuarios. El sistema logr√≥ una precisi√≥n satisfactoria (>85%) en la recuperaci√≥n de informaci√≥n correcta y contextualizada.  
Las respuestas fueron coherentes, con m√≠nima tendencia a alucinaciones, y permitieron validar la solidez de la base de conocimiento y el pipeline de RAG.

## üìÑ Conclusiones

- Se logr√≥ construir una **base de conocimiento estructurada y contextualizada** de Celsia a partir de fuentes oficiales.  
- La implementaci√≥n del modelo **Gemma 3 4B** ofrece una soluci√≥n **open source eficiente, reproducible y escalable**.  
- El enfoque **RAG con LangChain y ChromaDB** permite integrar b√∫squeda sem√°ntica y generaci√≥n natural de respuestas sin depender de APIs privadas.  
- Se deja preparada la arquitectura y la data para el **M√≥dulo 2**, donde se implementara la soluci√≥n RAG