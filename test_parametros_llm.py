"""
Script para Probar el Efecto de los Par√°metros del LLM
Verifica que temperatura, top_k y top_p realmente afecten las respuestas
"""

from langchain_ollama import ChatOllama
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

print("=" * 80)
print("üß™ PRUEBA DE PAR√ÅMETROS DEL LLM")
print("=" * 80)

# Configurar embeddings y retriever
embeddings = OllamaEmbeddings(
    model="nomic-embed-text",
    base_url="http://localhost:11434"
)

vectorstore = Chroma(
    persist_directory="./chromadb_storage",
    embedding_function=embeddings,
    collection_name="rag_collection"
)

retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5, "fetch_k": 20, "lambda_mult": 0.5}
)

# Prompt simple
prompt = PromptTemplate(
    template="""Bas√°ndote en el siguiente contexto, responde la pregunta de forma clara y concisa.

Contexto: {context}

Pregunta: {question}

Respuesta:""",
    input_variables=["context", "question"]
)

def formato_docs(docs):
    return "\n\n".join([doc.page_content for doc in docs])

# Pregunta de prueba
pregunta = "¬øQu√© es Celsia y qu√© servicios ofrece?"

print(f"\n‚ùì Pregunta de prueba: {pregunta}\n")

# ===== TEST 1: TEMPERATURA =====
print("=" * 80)
print("üå°Ô∏è TEST 1: EFECTO DE LA TEMPERATURA")
print("=" * 80)
print("Temperatura baja (0.1) = Respuestas m√°s deterministas y repetitivas")
print("Temperatura alta (0.9) = Respuestas m√°s creativas y variadas")

temperaturas = [0.1, 0.5, 0.9]

for temp in temperaturas:
    print(f"\n{'‚îÄ' * 80}")
    print(f"üî• Temperatura: {temp}")
    print(f"{'‚îÄ' * 80}")
    
    llm = ChatOllama(
        model="qwen3:4b",
        base_url="http://localhost:11434",
        temperature=temp,
        top_k=40,
        top_p=0.9
    )
    
    rag_chain = (
        {"context": retriever | formato_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # Hacer 3 invocaciones para ver variabilidad
    print("\nRespuestas (3 intentos):")
    for i in range(3):
        respuesta = rag_chain.invoke(pregunta)
        print(f"\n  [{i+1}] {respuesta[:150]}...")

# ===== TEST 2: TOP-K =====
print("\n" + "=" * 80)
print("üî¢ TEST 2: EFECTO DE TOP-K")
print("=" * 80)
print("Top-k bajo (5) = Solo considera las 5 palabras m√°s probables")
print("Top-k alto (80) = Considera m√°s opciones, m√°s variedad")

top_ks = [5, 40, 80]

for top_k in top_ks:
    print(f"\n{'‚îÄ' * 80}")
    print(f"üéØ Top-K: {top_k}")
    print(f"{'‚îÄ' * 80}")
    
    llm = ChatOllama(
        model="qwen3:4b",
        base_url="http://localhost:11434",
        temperature=0.7,  # Temperatura media para ver efecto
        top_k=top_k,
        top_p=0.9
    )
    
    rag_chain = (
        {"context": retriever | formato_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("\nRespuestas (2 intentos):")
    for i in range(2):
        respuesta = rag_chain.invoke(pregunta)
        print(f"\n  [{i+1}] {respuesta[:150]}...")

# ===== TEST 3: TOP-P =====
print("\n" + "=" * 80)
print("üìä TEST 3: EFECTO DE TOP-P (Nucleus Sampling)")
print("=" * 80)
print("Top-p bajo (0.3) = Solo palabras con alta probabilidad acumulada")
print("Top-p alto (0.95) = Permite m√°s diversidad en selecci√≥n")

top_ps = [0.3, 0.7, 0.95]

for top_p in top_ps:
    print(f"\n{'‚îÄ' * 80}")
    print(f"üé≤ Top-P: {top_p}")
    print(f"{'‚îÄ' * 80}")
    
    llm = ChatOllama(
        model="qwen3:4b",
        base_url="http://localhost:11434",
        temperature=0.7,
        top_k=40,
        top_p=top_p
    )
    
    rag_chain = (
        {"context": retriever | formato_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("\nRespuestas (2 intentos):")
    for i in range(2):
        respuesta = rag_chain.invoke(pregunta)
        print(f"\n  [{i+1}] {respuesta[:150]}...")

# ===== RESUMEN =====
print("\n" + "=" * 80)
print("üìã RESUMEN: C√ìMO INTERPRETAR LOS RESULTADOS")
print("=" * 80)

print("""
‚úÖ Los par√°metros EST√ÅN funcionando si observas:

1. TEMPERATURA:
   - Temp baja (0.1): Las 3 respuestas son casi id√©nticas
   - Temp alta (0.9): Las 3 respuestas var√≠an considerablemente

2. TOP-K:
   - Top-k bajo (5): Vocabulario m√°s limitado, frases m√°s predecibles
   - Top-k alto (80): Vocabulario m√°s amplio, mayor variedad l√©xica

3. TOP-P:
   - Top-p bajo (0.3): Respuestas m√°s conservadoras
   - Top-p alto (0.95): Respuestas m√°s exploratorias

‚ùå Los par√°metros NO est√°n funcionando si:
   - Todas las respuestas son id√©nticas sin importar los valores
   - No hay diferencia entre temperatura 0.1 y 0.9
   - Las variaciones son aleatorias y no siguen el patr√≥n esperado

üí° NOTA: Con temperatura=0.0, el modelo es completamente determinista,
   por lo que top-k y top-p tienen poco efecto.
""")

print("=" * 80)
print("‚úÖ PRUEBA COMPLETADA")
print("=" * 80)
