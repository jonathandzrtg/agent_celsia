{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Visualizador Din√°mico de Chunks - Celsia\n",
    "\n",
    "Notebook para explorar y analizar los chunks procesados de Celsia de forma interactiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 2 chunks\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m chunks_data \u001b[38;5;241m=\u001b[39m load_chunks_data()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks_data:\n\u001b[1;32m---> 19\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä DataFrame creado con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m filas y \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columnas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìã Columnas disponibles: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\j-h-o\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    776\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    777\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    778\u001b[0m     )\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\j-h-o\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\j-h-o\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\j-h-o\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n",
      "\u001b[1;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "# üìÇ Cargar datos de chunks\n",
    "def load_chunks_data(filename='celsia_processed_20251015_223656_chunks.json'):\n",
    "    \"\"\"Carga los datos de chunks desde el archivo JSON\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"‚úÖ Datos cargados: {len(data)} chunks\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Archivo no encontrado: {filename}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ùå Error al decodificar JSON: {filename}\")\n",
    "        return None\n",
    "\n",
    "# Cargar datos\n",
    "chunks_data = load_chunks_data()\n",
    "if chunks_data:\n",
    "    df = pd.DataFrame(chunks_data)\n",
    "    print(f\"üìä DataFrame creado con {len(df)} filas y {len(df.columns)} columnas\")\n",
    "    print(f\"üìã Columnas disponibles: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Vista general de los datos\n",
    "if chunks_data:\n",
    "    print(\"üìà RESUMEN GENERAL\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total de chunks: {len(df)}\")\n",
    "    \n",
    "    # Informaci√≥n por columnas\n",
    "    for col in df.columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        print(f\"{col}: {non_null}/{len(df)} valores no nulos\")\n",
    "    \n",
    "    print(\"\\nüìä PRIMERAS 5 FILAS:\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Explorador Interactivo de Chunks\n",
    "def show_chunk_details(index):\n",
    "    \"\"\"Muestra los detalles de un chunk espec√≠fico\"\"\"\n",
    "    if index < 0 or index >= len(df):\n",
    "        print(f\"‚ùå √çndice fuera de rango. Use 0-{len(df)-1}\")\n",
    "        return\n",
    "    \n",
    "    chunk = df.iloc[index]\n",
    "    \n",
    "    print(f\"üîç CHUNK #{index}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        value = chunk[col]\n",
    "        if pd.notna(value):\n",
    "            if col == 'content' and len(str(value)) > 200:\n",
    "                print(f\"üìÑ {col}: {str(value)[:200]}...\")\n",
    "            else:\n",
    "                print(f\"üìã {col}: {value}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Ejemplo: mostrar el primer chunk\n",
    "if chunks_data and len(df) > 0:\n",
    "    show_chunk_details(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé B√∫squeda y filtrado de chunks\n",
    "def search_chunks(keyword, column='content'):\n",
    "    \"\"\"Busca chunks que contengan una palabra clave\"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f\"‚ùå Columna '{column}' no existe\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    mask = df[column].astype(str).str.contains(keyword, case=False, na=False)\n",
    "    results = df[mask]\n",
    "    \n",
    "    print(f\"üîç B√∫squeda: '{keyword}' en columna '{column}'\")\n",
    "    print(f\"üìä Resultados encontrados: {len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Funci√≥n para b√∫squeda interactiva\n",
    "def interactive_search():\n",
    "    keyword = input(\"üîç Ingrese palabra clave para buscar: \")\n",
    "    column = input(f\"üìã Ingrese columna para buscar (default: content): \") or 'content'\n",
    "    \n",
    "    results = search_chunks(keyword, column)\n",
    "    if len(results) > 0:\n",
    "        print(f\"\\nüìã Primeros {min(5, len(results))} resultados:\")\n",
    "        display(results.head())\n",
    "        \n",
    "        if len(results) > 5:\n",
    "            show_all = input(f\"\\n¬øMostrar todos los {len(results)} resultados? (y/n): \")\n",
    "            if show_all.lower() == 'y':\n",
    "                display(results)\n",
    "    else:\n",
    "        print(\"‚ùå No se encontraron resultados\")\n",
    "\n",
    "print(\"üí° Use interactive_search() para buscar chunks\")\n",
    "print(\"üí° Use search_chunks('palabra_clave', 'columna') para b√∫squedas directas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà An√°lisis estad√≠stico de los chunks\n",
    "if chunks_data:\n",
    "    print(\"üìä AN√ÅLISIS ESTAD√çSTICO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # An√°lisis de longitud de contenido\n",
    "    if 'content' in df.columns:\n",
    "        df['content_length'] = df['content'].astype(str).str.len()\n",
    "        print(f\"üìè Longitud de contenido:\")\n",
    "        print(f\"  - Promedio: {df['content_length'].mean():.1f} caracteres\")\n",
    "        print(f\"  - Mediana: {df['content_length'].median():.1f} caracteres\")\n",
    "        print(f\"  - M√≠nimo: {df['content_length'].min()} caracteres\")\n",
    "        print(f\"  - M√°ximo: {df['content_length'].max()} caracteres\")\n",
    "    \n",
    "    # An√°lisis por categor√≠as\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        if col not in ['content'] and df[col].notna().sum() > 0:\n",
    "            unique_values = df[col].value_counts()\n",
    "            if len(unique_values) < 20:  # Solo mostrar si no hay demasiadas categor√≠as\n",
    "                print(f\"\\nüìä Distribuci√≥n de {col}:\")\n",
    "                for value, count in unique_values.items():\n",
    "                    print(f\"  - {value}: {count} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualizaciones\n",
    "if chunks_data and 'content_length' in df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('üìä An√°lisis Visual de Chunks - Celsia', fontsize=16)\n",
    "    \n",
    "    # Histograma de longitud de contenido\n",
    "    axes[0, 0].hist(df['content_length'], bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('üìè Distribuci√≥n de Longitud de Contenido')\n",
    "    axes[0, 0].set_xlabel('Caracteres')\n",
    "    axes[0, 0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # Box plot de longitud\n",
    "    axes[0, 1].boxplot(df['content_length'])\n",
    "    axes[0, 1].set_title('üì¶ Box Plot - Longitud de Contenido')\n",
    "    axes[0, 1].set_ylabel('Caracteres')\n",
    "    \n",
    "    # Si hay columnas categ√≥ricas, hacer gr√°ficos\n",
    "    categorical_cols = [col for col in df.columns if df[col].dtype == 'object' and col != 'content']\n",
    "    \n",
    "    if len(categorical_cols) > 0:\n",
    "        col = categorical_cols[0]\n",
    "        if df[col].notna().sum() > 0:\n",
    "            value_counts = df[col].value_counts().head(10)\n",
    "            axes[1, 0].bar(range(len(value_counts)), value_counts.values)\n",
    "            axes[1, 0].set_title(f'üìä Top 10 - {col}')\n",
    "            axes[1, 0].set_xticks(range(len(value_counts)))\n",
    "            axes[1, 0].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Timeline si hay fechas\n",
    "    date_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "    if date_cols:\n",
    "        col = date_cols[0]\n",
    "        try:\n",
    "            dates = pd.to_datetime(df[col], errors='coerce')\n",
    "            dates = dates.dropna()\n",
    "            if len(dates) > 0:\n",
    "                axes[1, 1].hist(dates, bins=20, alpha=0.7, color='lightgreen')\n",
    "                axes[1, 1].set_title(f'üìÖ Distribuci√≥n Temporal - {col}')\n",
    "                axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        except:\n",
    "            axes[1, 1].text(0.5, 0.5, 'No hay datos de fecha v√°lidos', ha='center', va='center')\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No hay columnas de fecha', ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéõÔ∏è Panel de Control Interactivo\n",
    "def control_panel():\n",
    "    \"\"\"Panel de control para navegar por los chunks\"\"\"\n",
    "    if not chunks_data:\n",
    "        print(\"‚ùå No hay datos cargados\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nüéõÔ∏è  PANEL DE CONTROL - CHUNKS CELSIA\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"1. üëÅÔ∏è  Ver chunk espec√≠fico (por √≠ndice)\")\n",
    "        print(\"2. üîç Buscar chunks\")\n",
    "        print(\"3. üìä Mostrar estad√≠sticas\")\n",
    "        print(\"4. üìã Listar primeros 10 chunks\")\n",
    "        print(\"5. üé≤ Ver chunk aleatorio\")\n",
    "        print(\"6. üíæ Exportar resultados filtrados\")\n",
    "        print(\"0. ‚ùå Salir\")\n",
    "        \n",
    "        choice = input(\"\\n‚û§ Seleccione una opci√≥n: \")\n",
    "        \n",
    "        if choice == '0':\n",
    "            print(\"üëã ¬°Hasta luego!\")\n",
    "            break\n",
    "        elif choice == '1':\n",
    "            try:\n",
    "                index = int(input(f\"Ingrese √≠ndice (0-{len(df)-1}): \"))\n",
    "                show_chunk_details(index)\n",
    "            except ValueError:\n",
    "                print(\"‚ùå Ingrese un n√∫mero v√°lido\")\n",
    "        elif choice == '2':\n",
    "            interactive_search()\n",
    "        elif choice == '3':\n",
    "            display(df.describe())\n",
    "        elif choice == '4':\n",
    "            display(df.head(10))\n",
    "        elif choice == '5':\n",
    "            random_index = np.random.randint(0, len(df))\n",
    "            print(f\"üé≤ Chunk aleatorio (√≠ndice {random_index}):\")\n",
    "            show_chunk_details(random_index)\n",
    "        elif choice == '6':\n",
    "            filename = input(\"Nombre del archivo (sin extensi√≥n): \") + \".csv\"\n",
    "            df.to_csv(filename, index=False, encoding='utf-8')\n",
    "            print(f\"‚úÖ Datos exportados a: {filename}\")\n",
    "        else:\n",
    "            print(\"‚ùå Opci√≥n no v√°lida\")\n",
    "\n",
    "print(\"üí° Use control_panel() para acceder al panel de control interactivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ An√°lisis de calidad y duplicados\n",
    "if chunks_data:\n",
    "    print(\"üîç AN√ÅLISIS DE CALIDAD Y DUPLICADOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # An√°lisis de calidad si existe la columna\n",
    "    if 'quality_score' in df.columns:\n",
    "        quality_stats = df['quality_score'].describe()\n",
    "        print(\"üìä Estad√≠sticas de Calidad:\")\n",
    "        for stat, value in quality_stats.items():\n",
    "            print(f\"  - {stat}: {value:.3f}\")\n",
    "        \n",
    "        # Chunks de alta y baja calidad\n",
    "        high_quality = df[df['quality_score'] > 0.8]\n",
    "        low_quality = df[df['quality_score'] < 0.5]\n",
    "        print(f\"\\nüåü Chunks de alta calidad (>0.8): {len(high_quality)}\")\n",
    "        print(f\"‚ö†Ô∏è  Chunks de baja calidad (<0.5): {len(low_quality)}\")\n",
    "    \n",
    "    # An√°lisis de duplicados\n",
    "    if 'content' in df.columns:\n",
    "        duplicates = df['content'].duplicated().sum()\n",
    "        print(f\"\\nüîÑ Duplicados exactos encontrados: {duplicates}\")\n",
    "        \n",
    "        # Chunks muy similares (por longitud)\n",
    "        if 'content_length' in df.columns:\n",
    "            similar_lengths = df.groupby('content_length').size()\n",
    "            similar_lengths = similar_lengths[similar_lengths > 1]\n",
    "            print(f\"üìè Grupos con longitud similar: {len(similar_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Instrucciones de Uso\n",
    "\n",
    "### Funciones Principales:\n",
    "\n",
    "1. **`control_panel()`** - Panel interactivo para navegar\n",
    "2. **`show_chunk_details(index)`** - Ver detalles de un chunk\n",
    "3. **`search_chunks('keyword', 'column')`** - Buscar en los chunks\n",
    "4. **`interactive_search()`** - B√∫squeda interactiva\n",
    "\n",
    "### Ejemplos de Uso:\n",
    "\n",
    "```python\n",
    "# Ver el chunk n√∫mero 5\n",
    "show_chunk_details(5)\n",
    "\n",
    "# Buscar chunks que contengan \"energ√≠a\"\n",
    "results = search_chunks('energ√≠a')\n",
    "\n",
    "# Panel de control interactivo\n",
    "control_panel()\n",
    "```\n",
    "\n",
    "### Tips:\n",
    "- Los datos se cargan autom√°ticamente al ejecutar las celdas\n",
    "- Use el panel de control para una navegaci√≥n f√°cil\n",
    "- Las visualizaciones se generan autom√°ticamente\n",
    "- Puede exportar resultados filtrados a CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
